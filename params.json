{"name":"Avro VS Parquet benchmarks","tagline":"A Read&Count Benchmark of Parquet & Avro using spark.","body":"### 关于Parquet\r\n\r\nParquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，细节请参考http://parquet.apache.org/documentation/latest/。\r\n\r\n##列式存储\r\n\r\n列式存储和行式存储相比有哪些优势呢？\r\n\r\n可以跳过不符合条件的数据，只读取需要的数据，降低IO数据量。\r\n压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样的，可以使用更高效的压缩编码（例如Run Length Encoding和Delta Encoding）进一步节约存储空间。\r\n只读取需要的列，支持向量运算，能够获取更好的扫描性能。\r\n适配多种计算框架\r\n\r\nParquet是语言无关的，而且不与任何一种数据处理框架绑定在一起，适配多种语言和组件，能够与Parquet配合的组件有：\r\n\r\n查询引擎: Hive, Impala, Pig, Presto, Drill, Tajo, HAWQ, IBM Big SQL\r\n\r\n计算框架: MapReduce, Spark, Cascading, Crunch, Scalding, Kite\r\n\r\n数据模型: Avro, Thrift, Protocol Buffers, POJOs\r\n\r\n## 性能\r\n\r\nParquet就是基于Google的Dremel系统的数据模型和算法实现的。核心思想是使用“record shredding and assembly algorithm”来表示复杂的嵌套数据类型，同时辅以按列的高效压缩和编码技术，实现降低存\r\n\r\n储空间，提高IO效率，降低上层应用延迟。\r\n\r\nParquet列式存储带来的性能上的提高在业内已经得到了充分的认可，特别是当你们的表非常宽（column非常多）的时候，Parquet无论在资源利用率还是性能上都优势明显。具体的性能指标详见参考文档。\r\n\r\nSpark已经将Parquet设为默认的文件存储格式，Cloudera投入了很多工程师到Impala+Parquet相关开发中，Hive/Pig都原生支持Parquet。Parquet现在为Twitter至少节省了1/3的存储空间，同时节省了大量的表\r\n\r\n扫描和反序列化的时间。这两方面直接反应就是节约成本和提高性能（详见benchmark）。\r\n\r\n\r\n### benchmark\r\n\r\n以邮箱的展示日志为例，比较了Avro和Parquet两种存储格式的性能：camus-2015/05/24的日志，5,361,809条记录，hadoop2.4，Spark1.3.1。\r\n结果详见： http://blog.csdn.net/zyq12345678/article/details/47725461\r\n\r\n\r\n备注：1. 测试代码详见AvroParquetBenchMark 2. 读取Avro是新老API性能差距较大，目前还未找到原因。\r\n\r\n### 与Avro\r\n\r\n之前新统计系统（Quipu）的日志都是用Avro做序列化和存储，鉴于Parquet的优势和对Avro的兼容，将HDFS上的存储格式改为Paruqet，并且只需做很小的改动就用原读取Avro的API读取Parquet，单列查询效率可\r\n\r\n以提高近一个数量级。\r\n\r\n## Schema\r\n\r\nParquet文件尾部存储了文件的元数据信息和统计信息，自描述的，方便解析。","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}